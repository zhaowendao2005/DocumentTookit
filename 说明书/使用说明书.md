## 文档处理集成工具 · 使用说明书（非技术版）

本说明书面向不懂编程的使用者，帮助您快速上手本工具，完成批量文档加工（由大模型自动抽取结构化结果）、错误重处理、文档格式转换、文本分割、CSV 合并与模型连通性测试等常见工作。

---

## 我能用它做什么
- 【批量处理】把一批 `.txt`/`.md`/`.docx` 文档交给大模型处理，自动生成标准 CSV 表格
- 【两种模式】
  - Classic：大模型直接产出 CSV
  - Structured：大模型先产出 JSON，再在本地严格校验/修复后转为 CSV（质量更稳，可回退 Classic）
- 【错误闭环】失败样本自动分类归档；支持“错误重处理批次”一键二次处理并自动清理错误清单
- 【文档转换】Word（.docx）批量转 Markdown（.md）
- 【文本分割】按正则/层级把长文切成结构化小段
- 【CSV 合并】把多个 CSV 合并为一个
- 【模型测试】快速检查各模型是否连通、响应时延与用量

---

## 使用前准备
- 操作系统：Windows 10/11（亦可在 macOS/Linux 使用）
- 必备软件：
  - Node.js 16 及以上（建议 LTS 版本）
  - Pandoc（仅当使用“DOCX 转 Markdown”时需要）
- 大模型服务：至少配置一个 OpenAI 兼容的服务（需 base_url 与 API Key）

---

## 一次性安装（首次使用）
1) 安装 Node.js：从官网安装 LTS 版本
2) 打开命令行，进入项目目录，安装依赖：
```bash
npm install
```
3) 复制并编辑配置文件：
```bash
# 复制示例为正式配置
cp config/env.yaml.example config/env.yaml
# Windows PowerShell 可用：copy config/env.yaml.example config/env.yaml
```
4) 打开并填写 `config/env.yaml`：
- 在 `providers` 中写入您的服务地址与 API Key
- 保持默认的目录配置即可（也可按需修改）

示例（简化版）：
```yaml
providers:
  - name: "OpenAI"
    base_url: "https://api.openai.com"
    api_key: "YOUR_OPENAI_API_KEY"
    models: ["gpt-4o-mini", "gpt-4o"]

directories:
  input_dir: "./data/input"
  output_dir: "./data/output"
  temp_dir: "./data/temp"
  candidate_tools_dir: "./sourcefiles"

processing:
  default_mode: "structured"   # classic | structured
  allow_fallback: true          # 结构化失败时回退 classic
  fallback_mode: "classic"

validation:
  enable_multiple_requests: true
  request_count: 3
  similarity_threshold: 0.8

network:
  connect_timeout_ms: 3000
  response_timeout_ms: 60000
```

可选：若要使用“DOCX 转 Markdown”，请安装 Pandoc 并确保命令行可运行 `pandoc --version`。

---

## 快速开始（最常用）
1) 在命令行进入项目根目录，启动程序：
```bash
node main.js
```
2) 屏幕上会出现主菜单：
- 🔄 批量LLM处理
- 📄 Docx转Markdown
- 🧪 模型测试
- 📊 CSV合并工具
- ✂️  文本分割工具
- 🧩 Colipot 预置方案
- ⚙️  配置管理 / 📊 查看状态 / ❌ 退出

3) 首次建议先点“⚙️ 配置管理 → 查看当前配置”，确认模型与目录无误。

---

## 典型工作流

### 1. 批量 LLM 处理（核心功能）
1) 选择“🔄 批量LLM处理”
2) 选择模型（来自 `config/env.yaml` 的 providers/models 列表）
3) 选择输出模式：
   - Classic：直接由模型输出 CSV
   - Structured：输出 rows JSON → 本地校验/修复 → CSV（推荐）
4) 选择输入方式：
   - 🎯 增强多选（推荐）：可勾选文件或整个目录（目录会递归包含支持的文件）
   - 📁 单目录：处理该目录内所有支持文件
   - 📄 多文件：手动选择多个文件
   - 🛠 错误重处理批次：列出历史失败批次，点选后仅处理失败样本
5) 若不是“错误重处理”，请选择输出目录（默认 `data/output`）
6) 可选参数：
   - 多次请求与相似度阈值（提升稳定性，耗时略增）
   - 网络超时设置（连接/响应）
   - 若选 Structured：选择提示词版本与“JSON 纠错回合数”（0–3）
   - 可选“结束后由 LLM 生成运行总结”
7) 执行中可按键盘 `s` 停止：
   - 第一次按：软停止（不再启动新请求，等待在途完成）
   - 再次按：硬停止（立即结束在途请求）
8) 查看结果：
   - 输出在 `data/output/时间戳/`
   - 成功文件：对应的 `.csv`
   - 运行总结：`run_summary.json` 与 `run_summary.md`
   - 失败样本：`error/` 目录，按原因分类（如 `timeout`、`validation_error` 等）

目录示例：
```text
data/output/
  └─ 2025-08-13T02-51-08/
      ├─ 01张三.csv
      ├─ 02李四.csv
      ├─ run_summary.json
      ├─ run_summary.md
      └─ error/
          ├─ error_manifest.json
          ├─ client_error/
          │   └─ error.json
          └─ fallback_failed/
              └─ error.json
```

小贴士：Structured 模式失败会自动尝试“回退 Classic”（若配置允许）。

### 2. 错误重处理闭环（修复失败样本）
- 在“选择输入方式”阶段选“🛠 错误重处理批次”
- 程序会按时间倒序列出历史批次，显示各错误类型数量
- 选中某批次后，系统会收集该批次的失败样本重新处理
- 成功后：
  - 结果回写原“时间戳目录”
  - 自动清理 `error/`：删除已修复的拷贝，并更新 `error_manifest.json`

### 3. DOCX → Markdown（可选）
- 从主菜单选择“📄 Docx转Markdown”
- 选择输入/输出目录
- 依赖 Pandoc，请确保已安装（否则会提示未安装）

### 4. 文本分割工具
- 从主菜单选择“✂️ 文本分割工具”
- 支持多级正则分割，预览树形结果，导出为 `.txt/.md/.yaml`
- 适合将长文分片，便于后续分批处理

### 5. CSV 合并工具
- 从主菜单选择“📊 CSV合并工具”
- 选择包含多个 CSV 的目录，系统会询问是否合并并生成时间戳命名的新文件

### 6. 模型测试
- 从主菜单选择“🧪 模型测试”
- 可测试单模型、某提供商全部模型或所有模型的连通性与响应时间
- 支持输出 JSON 报告

### 7. Colipot 预置方案（选配）
- 从主菜单选择“🧩 Colipot 预置方案”，在 `config/ColipotConfig/*.yaml` 中选一份方案一键跑批
- 适合团队将“模型/模式/输入/输出/阈值/修复回合”等操作打包成模板，交付使用

---

## 结果文件与报告
- `run_summary.json` / `run_summary.md`：本次运行的汇总（总数/成功/失败/回退、按类型统计）
- `error/error_manifest.json`：失败清单与分类汇总（用于“错误重处理批次”）
- `temp/`（内部使用）：存放中间 JSONL、校验报告等

---

## 常见问题（FAQ）
- Q：启动提示“配置文件不存在”/“providers 为空”？
  - A：请先复制 `config/env.yaml.example` 为 `config/env.yaml`，并正确填写 `providers`。
- Q：模型无法连接/超时？
  - A：检查 `base_url`、`api_key` 是否正确；适当增大 `network.response_timeout_ms`；或运行诊断：
```bash
node main.js --diag
```
- Q：DOCX 转 Markdown 报错“Pandoc 未安装”？
  - A：安装 Pandoc 并确保命令行可运行 `pandoc --version`。
- Q：CSV 表头不一致导致合并偏差？
  - A：合并时以第一份文件的表头为准，表头不同会跳过后续文件的表头行，仅合并数据行。
- Q：结果质量波动？
  - A：开启“多次请求 + 相似度阈值”会更稳；Structured 模式质量更稳定；必要时提高 `request_count`。
- Q：如何紧急停止？
  - A：运行中按 `s`：先软停，再按一次变为硬停。

---

## 术语解释（通俗版）
- Classic 模式：模型直接写出 CSV。快，但有时格式不稳。
- Structured 模式：模型先给 JSON，本地严格校验并自动修复，再转 CSV。稳，且可回退 Classic。
- 多次请求与相似度：同一文件多问几次，系统对比答案一致性并自动选择更靠谱的结果。
- 回退：Structured 失败时，自动再走一遍 Classic，尽量给出结果。

---

## 管理员/实施人员小贴士（选读）
- 提示词版本：`prompts/StructuredFileProcessor/Version1/` 可放置不同版本提示词（system/repair/schema）供选择
- Token 用量：系统会在后台记录真实/估算的用量统计，汇总写入运行总结
- Colipot 方案：把一次成功的批量配置保存为 `config/ColipotConfig/*.yaml`，方便甲方“一键复跑”

---

## 支持的文件类型
- 输入：`.txt`、`.md`、`.docx`
- 输出：`.csv`（主）、`.md`（转换）、部分中间 JSON/JSONL（内部）

---

## 附录：最小可用配置示例（节选）
```yaml
providers:
  - name: "OpenAI"
    base_url: "https://api.openai.com"
    api_key: "YOUR_OPENAI_API_KEY"
    models: ["gpt-4o-mini"]

directories:
  input_dir: "./data/input"
  output_dir: "./data/output"
  temp_dir: "./data/temp"
  candidate_tools_dir: "./sourcefiles"

processing:
  default_mode: "structured"
  allow_fallback: true
  fallback_mode: "classic"

validation:
  enable_multiple_requests: true
  request_count: 3
  similarity_threshold: 0.8
```

如需进一步定制（例如增加提供商、修改并发、替换提示词版本等），请联系实施人员协助。

---

祝您使用顺利！